## Key terms

-   Two types of representations
    -   Normal form
    -   Extensive form
-   Strategic decisions (based on rivals' actions)
    -   Pricing
    -   Advertising
    -   Product quality
    -   Monitoring employees
    -   Entry
    -   Coordination and bargaining
    -   Innovation
-   Types of equilibrium strategies
    -   Dominant
    -   Secure
    -   Nash
    -   Mixed
    -   Subgame perfect
-   Repeated games
    -   Are cooperative (collusive) outcomes supported as a Nash equilibrium?
    - Subgame perfect equilibrium as a set of moves that leads to a Nash equilibrium in each subgame
-   Trigger strategies
-   Interest rate
-   Indefinite or uncertain final period
-   Multistage games (e.g. Stackelberg leader-follower)

---

## Overview

> [!definition] Game theory
> Game theory is a general framework to aid decision making when agents' payoffs depend on the actions taken by other players

Almost all economic interactions are games.

Two leading frameworks:

-   cooperative
-   non-cooperative

Components of games:

-   **Players**: decision makers
-   **Strategies**: planned **actions** of players
-   **Payoffs**: outcomes resulting from strategy scenarios
-   **Order of play**: rules
-   **Frequency of play**, interaction

---

## Order of decisions

-   **Simultaneous-move games**:
    -   Game in which each player makes decisions without knowledge of the other players' decisions
    -   _e.g. Cournot, Bertrand_
-   **Sequential-move games**:
    -   Game in which one player makes a move after observing the other player's move
    -   _e.g. Stackelberg, chess_

---

## Frequence of Interaction

-   **One-shot game**:
    -   Game in which players interact to make decisions only once
-   **Repeated game**:
    -   Game in which players interact to make decisions more than once
    -   Discount factor $\boxed{\delta = \frac{1}{1+i}}$

---

## Decision strategies

> [!rule]
> -   **Dominant strategy**
>     -   A strategy that results in the highest payoff to a player regardless of the opponents' actions
>     -  For **all** possible moves of the other player!!
>     -   _E.g. Prisoner's dilemma: confessing is the dominant strategy_
>     
> -   **Secure strategy**
>     -   A strategy that guarantees the **highest payoff given the worst possible scenario**
>     -   _E.g. Prisoner's dilemma: both remaining silent is the secure strategy_
> 
> -   **Nash equilibrium strategy**
>     -   A condition describing a set of strategies in which **no player can improve their payoff** by **unilaterally changing** their of strategy, given the other players' strategies
>     -   "I'm doing the best I can given what you are doing. You're doing the best you can given what I am doing."
>     -   $\neq$ joint optimum! One-shot Nash can be worse for everyone than coordinated outcomes (e.g. low-price equilibrium)
>     -   _E.g. Prisoner's dilemma: both confessing is the Nash equilibrium_
---

## Nash equilibrium

> [!rule] Nash equilibrium
> A Nash equilibrium is a set of strategies in which **no player can improve their payoff by unilaterally changing their strategy**, given the strategies of the other players.

-   "I'm doing the best I can given what you are doing. You're doing the best you can given what I am doing."
-   $\neq$ joint optimum! 
-   One-shot Nash can be worse for everyone than coordinated outcomes (e.g. low-price equilibrium)

---

## Representations of games

### Normal-Form game

-   Matrix representation

![[images/9-normal-form-game.jpg]]

**Prisoner's dilemma**: there's a smart police officer who interrogates 2 prisoners separately. Each prisoner has two strategies: to confess or to remain silent. The payoffs are years in prison.

|                     | Prisoner B: Confess | Prisoner B: Silent |
| ------------------- | ------------------- | ------------------ |
| Prisoner A: Confess | (1, 1)              | (0, 5)             |
| Prisoner A: Silent  | (5, 0)              | (0, 0)             |

Where the numbers in parentheses represent $(\text{years in prison for } A, \text{years in prison for } B)$.

### Extensive-Form game

-   Tree representation
-   Decision nodes
-   Branches indicate possible actions
-   Terminal nodes indicate payoffs: $(\text{payoff to player 1}, \text{payoff to player 2})$

![[images/9-multistage.jpg]]

---

## Simultaneous-move, one-shot games

Mostly use the **normal-form representation**.

#### No Nash equilibrium

If there are no Nash equilibria in pure strategies, there may be in **mixed (randomized) strategies**: a player randomizes over two or more available actions in order to keep rivals from being able to predict what they will do.

> [!rule] Mixed strategy Nash equilibrium
> If **no pure strategy Nash equilibrium** exists, **randomize**.

### Applications of One-Shot Games

-   **Coordination games**
-   **Advertising and Quality decisions**
-   **Monitoring employees**
-   **Nash bargaining**

---

## Multishot games = Multi-stage games

Multistage games examine **timing of decisisions** in games.

-   players make **sequential**, rather than simultaneous, decisions
-   mostly represented by an **extensive form game** (game **tree**)
-   but also possible to extend normal form games to multistage games!

> [!formula] Discount factor and interest rate
>
> $$
> \boxed{\text{Discount factor } \delta = \frac{1}{1+i}}
> $$
>
> Where $\boxed{i = \text{interest rate}}$

### Recap: Present Value of Future Payoffs

> [!formula] Present value of a future payoff
>
> $$
> PV = \sum_{t=0}^T \frac{FV}{(1+i)^t} = \sum_{t=0}^T FV \cdot \delta^t
> $$

### Extending a single-shot normal form game to $n$ stages

Work **backwards** from the last stage to the first stage:

1. Start from the normal form table of the one-shot game
   $\quad \Rightarrow$ this is the last stage $n$
2. Determine the payoffs (e.g. Nash equilibrium _NE_) for this last stage
3. Create a new normal form table for stage $n-1$
4. Add the payoffs from stage $n$ to the payoffs from stage $n-1$, discounted by $\delta$.
   $\quad \Rightarrow$ this is an **aggregated matrix**
5. Apply **best response analysis** to find the equilibrium for stage $n-1$
6. Keep repeating steps 3-5 until you reach stage 1.

> [!formula] Total equilibrium
>
> $$
> \text{Total Payoff} = \text{Payoff}(s_1) + \delta \times \text{Payoff}(s_2) + \delta^2 \times \text{Payoff}(s_3) + \ldots + \delta^{n-1} \times \text{Payoff}(s_n)
> $$

### Equilibrium in Multi-stage Games: SPE

Nash equilibrium **may not be reasonable** in multi-stage games, because players may have incentives to deviate from the equilibrium path in future stages.

> [!formula] Subgame Perfect Equilibrium (SPE)
> A **<u>set</u> of strategies** that **constitutes a Nash equilibrium in every subgame** of the original game and allows no player to improve his own payoff at any stage of the game by changing strategies.
>
> $$
> \text{SPE} = \{(SP_{1,1}, SP_{1,2}), (SP_{2,1}, SP_{2,2}), \ldots , (SP_{n,1}, SP_{n,2})\}
> $$

> [!rule] Credibility of moves in multi-stage games
> In multi-stage games, we should consider if moves are **credible**. A firm may threaten to take an action in the future, but if taking that action is **not in its best interest** when the time comes, the **threat is not credible**.

---

## Trigger strategies

> [!rule] Cooperative outcome with trigger strategies
> The **cooperative outcome** can be **sustained** in an _infinitely repeated game_ with the following **trigger strategy**:
>
> -   Cooperate provided that no player has ever cheated
> -   If any cheats, punish the player by choosing the **one-shot Nash equilibrium strategy forever after**

-   $i$ = Interest rate
-   $\pi^\text{coop}$ = Cooperative one-shot payoff to a player
-   $\pi^\text{chat}$ = Maximum one-shot payoff to a player from cheating on the collusive outcome
-   $\pi^N$ = One-shot Nash equilibrium payoff to a player

Assume $$\frac{\pi^\text{chat} - \pi^\text{coop}}{\pi^\text{coop} - \pi^N} \leq \frac{1}{i}$$

---

## Infinitely repeated games

### Same payoff each period: $PV(\text{cooperation})$

If the profit $\pi_\infty$ is the **same in each period over an infinite time horizon** (e.g. cooperative outcome), the present value of the firm is given by:

$$
\begin{aligned}
PV_\text{firm} &= \sum_{t=0}^{\infty} \frac{\pi_\infty}{(1+i)^t} \\
&= \pi_\infty \sum_{t=0}^{\infty} \left(\frac{1}{1+i}\right)^t \\
&= \pi_\infty \left(\frac{1+i}{i}\right)
\end{aligned}
$$

> [!formula] Present value of a firm with infinite horizon profits
>
> $$
> \boxed{PV_\text{firm}^{\pi_\infty} = \pi_\infty \left(\frac{1+i}{i}\right) = \pi_\infty \left( \frac{1}{1-\delta} \right)}
> $$

> [!rule] Cooperative present value in infinite games
>
> $$
> \begin{aligned}
> \boxed{PV(\text{cooperation})} &= \sum_{t=0}^{\infty} \pi^\text{coop} \cdot \delta^t \\
> &= \boxed{\pi^\text{coop} \left( \frac{1}{1-\delta} \right)}
> \end{aligned}
> $$

### Infinite games with trigger strategies: $PV(\text{cheat})$

-   While cooperating, each firm earns $\pi^\text{coop}$ each period.
-   If a firm cheats:
    -   it earns $\pi^\text{chat}$ once
    -   the other firms punish by **playing the one-shot Nash equilibrium forever after**
    -   so the cheating firm earns $\pi^N$ forever after

> [!rule] Present value of a cheating firm
>
> $$
> \begin{aligned}
> \boxed{PV(\text{cheat})} &= \pi^\text{cheat} + \sum_{t=1}^{\infty} \pi^N \cdot \delta^t \\
> &= \pi^\text{cheat} + \pi^N \left( \sum_{t=0}^{\infty} \delta^t - 1 \right) \\
> &= \pi^\text{cheat} + \pi^N \left( \frac{1}{1-\delta} - 1 \right) \\
> &= \boxed{\pi^\text{cheat} + \pi^N \left( \frac{\delta}{1-\delta} \right)}
> \end{aligned}
> $$

In this case, the **cooperation** (i.e. $PV(\text{cooperation})$) is subgame perfect if:

> [!rule] Condition for SUBGAME PERFECT COOPERATION in infinite games
>
> $$
> \boxed{PV(\text{cooperation}) \geq PV(\text{cheat})}
> $$

---

### Factors affecting collusion in pricing games

Sustaining collusion via trigger strategies is easier when firms know

-   _who_ their _rivals_ are, so they now whom to punish
-   _who_ their _rival's customers_ are, so they can "steal" those customers with lower prices
-   _when_ their rivals deviate/cheat, so they can punish them immediately
-   be able to successfully punish rival

Also,

-   number of firms in the market,
-   firm size,
-   history of the market,
-   punishment mechanisms

---

## Finitely repeated games

Games in which a **one-shot game is repeated a finite number of times**.
Variations: games in which players

-   know when the game will end
-   do **not** know when the game will end

### Uncertain Final Period

Game will end after a given play with **probability $\theta$**

> [!rule] Cooperative outcome with uncertain final period
> **No incentive to cheat** on the collusive outcome in a _finitely repeated game with uncertain final period_ if:
>
> $$
> \boxed{\Pi_A^\text{cheat} = \pi_A^\text{cheat} \leq \Pi_A^\text{coop} = \frac{\pi_A^\text{coop}}{\theta}}
> $$

Where $\Pi_A^\text{cheat}$ = **<u>Present value</u>** of firm A when it cheats
and $\Pi_A^\text{coop}$ = Present value of firm A when it cooperates.

Why is the present value of cooperating equal to $\frac{\pi_A^\text{coop}}{\theta}$?

-   Each period, there is a probability $\theta$ that the game ends.
-   Therefore, the expected number of periods the game continues is
    $$
    E(\text{number of periods}) = \frac{1}{\theta}
    $$

### Known Final Period: End-of-Period problem

When the game is repeated some **known, finite number of times** and there is **only one Nash equilibrium**, then **collusion cannot work**, because of the **end-of-period problem**.

> [!definition] End-of-period problem
>
> -   Because players know when the game will end, they have an **<u>incentive to cheat in the final period</u>**.
> -   The last round is thus played as a one-shot game and both players cheat (Nash equilibrium).
> -   In the second to last round, both players know that the other will cheat in the last round, so they have an incentive to cheat in the second to last round as well.
> -   This reasoning continues all the way back to the first round, so the **<u>only subgame perfect equilibrium is the one-shot Nash equilibrium played in every period</u>**.

> [!rule] End-of-period problem outcome
> In a finitely repeated game with a known final period, because of the **end-of-period problem**, firms have an incentive to cheat in the final period and the **only subgame perfect equilibrium is the one-shot Nash equilibrium played in every period**.

Examples of end-of-period problems:

-   **Resignations and quits**
    -   Employees may work hard during most of their tenure, but as they approach their planned resignation date, they may reduce effort since they no longer care about future repercussions.
-   **The "Snake-Oil" salesman**
    -   A salesperson goes from town to town selling a product of dubious quality.
    -   Since the salesperson will not return to the same town, there is no incentive to maintain a good reputation, so the only subgame perfect equilibrium is to sell low-quality products at high prices.
-   **Tourist trap restaurants**
    -   Restaurants located in tourist areas may have little incentive to provide good service or high-quality food, since tourists are unlikely to return.
